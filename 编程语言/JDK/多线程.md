##### 线程生命周期

```
NEW：使用 new 操作符创建的新的线程对象的初始状态
RUNNABLE：可运行状态，又分为两种
	READY：RUNNING状态的线程 被调度/yield ,线程变为READY
	RUNNING：READY的线程被调度，变成变为RUNNAING
TERMINATED：RUNNABLE的线程执行完毕，一般是run方法中的逻辑执行完毕
BLOCKED：RUNNABLE状态的线程调用同步代码块，拿不到锁的时候
    同步阻塞、等待阻塞(wait)、其他阻塞(sleep、join、IO操作)
WAITING：RUNNABLE状态的线程调用wait、join、LockSupport.park方法的时候
TIME_WAITING：同WAITING，不过是方法中参数带时间，如sleep(时间)
```

##### 线程的中断和复位

```
终止：
thread.interrupt()方法底层是通过设置一个boolean的标志位来标志线程是否应该中断，调用该方法可以将中断标志位设置为true,并唤醒处于阻塞状态下的当前线程
thread.currentThread.isInterrupt()可以获得底层的中断标志位

重置：
Thread.interrupted()可以使中断标志位复位(回到初始状态false)
中断一个处于阻塞状态(join、wait、sleep、queue.take)的线程，会抛出InterruptedException(相当于系统给了一个停止阻塞线程的入口，可捕获异常处理)
线程抛出InterruptedException也会重置中断标志位
```
[##### 锁升级](https://gitee.com/seeks/blogs/blob/master/images/JDK-%E5%81%8F%E5%90%91%E9%94%81.png)

```
大部分情况下,加锁的代码不仅仅不存在多线程竞争,而且总是由同一个线程多次获得
偏向锁(cas乐观锁-只需一次CAS操作写入ThreadId和偏向锁标识)：只有同一个线程去访问临界区(绝大多时候)；
    目标：减少在无竞争且只有一个线程使用锁的情况下使用轻量锁产生的性能消耗
    过程：cas设置成功则执行同步代码块，失败且获取到偏向锁的线程不是当前线程，则表示其他线程获取到偏向锁,且存在线程竞争,故执行锁升级到轻量级锁
轻量级锁(自旋锁-申请和释放时各需一次CAS操作)：两个线程交替访问临界区(绝大部分线程在获得锁以后，会在非常短的时间内释放)  ->  自旋(线程释放锁很快，一直循环重试，反而效率很高)
    目标：减少无实际竞争情况下使用重量锁产生的性能消耗
	问题：自旋会占用CPU资源，所以在指定的自旋次数后，还没有获得轻量级锁，锁会膨胀成重量级锁 -> 阻塞
	自旋次数：1:设置(preBlockSpin 默认为10) 2:自适应自旋
重量级锁(Mutex)：多个线程同时访问临界区(直接调用objectMonitor的enter和exit，它和操作系统的互斥量直接对应，系统调用会引起用户态和和核心态的切换等问题，性能消耗大。)      阻塞(升级到重量级锁之后，没有获得锁的线程会被阻塞 BLOCKED)
	monitorEnter ------【Monitor】------monitorEnter成功(失败进去SynchronnizedQueue)------获得对象锁 ------ monitorExit
每一个对象都有一个ObjectMonitor,monitor依赖操作系统的MutexLock(互斥锁)来实现的
```

##### 内存一致性
##### 

```
总线锁(锁粒度太大)和缓存锁(缓存一致性协议，最常见的就是 MESI协议)
M: 被修改（Modified)
E: 独享的（Exclusive)
S: 共享的（Shared)
I: 无效的（Invalid）
```

##### 屏障

```
CPU乱序执行 -> 重排序 -> 可见性问题
CPU层提供指令 -> 内存屏障(读屏障、写屏障、全屏障)
通过内存屏障禁止重排序，用来解决可见性问题

```
##### 重排序

```
不管怎么重排序，对于当个线程的执行结果不能变
volatile通过禁止指令重排达到可见性，不解决原子性问题
synchronized 解决原子性、可见性、有序性
```
##### happen-before

```
如果一个操作执行的结果需要对另一个操作可见,那么这两个操作必须要存在happens-before 关系
1、一个线程中的每个操作，happens-before于该线程中的任意后续操作
2、对于volatile修饰的变量的写的操作,一定happen-before后续对于 volatile 变量的读操作
3、传递性规则
4、start规则,主线程在调用子线程start操作之前的任何操作，happens-before子线程中的任何操作
5、join 规则,如果线程A执行操作ThreadB.join()并成功返回，那么线程 B 中的任意操作happens-before于线程A从ThreadB.join()返回
6、监视器锁的规则,对一个锁的解锁,happens-before于随后对这个锁的加锁
```

##### 

```
ReentrantLock：表示重入锁，它是唯一一个实现了 Lock接口的类
ReentrantReadWriteLock：重入读写锁，它实现了 ReadWriteLock 接口，在这个类中维护了两个锁，一个是ReadLock，一个是WriteLock，他们都分别实现了Lock接口
StampedLock： stampedLock是JDK8引入的新的锁机制，可以简单认为是读写锁的一个改进版本，读写锁虽然通过分离读和写的功能使得读和读之间可以完全并发，但是读和写是有冲突的，如果大量的读线程存在，可能会引起写线程的饥饿。stampedLock是一种乐观的读策略，使得乐观锁完全不会阻塞写线程
```


##### AQS

```
同步队列
AQS 的功能分为两种：独占和共享
AQS 队列内部维护的是一个FIFO的双向链表,这种结构的特点是每个数据结构都有两个指针,分别指向直接的后继节点和直接前驱节点,每个 Node 其实是由线程封装，当线程争抢锁失败后会封装成Node加入到 ASQ 队列中去；当获取锁的线程释放锁以后，会从队列中唤醒一个阻塞的节点(线程)。
condition队列
五种状态：1(CANCELLED) 0(default) -1(SIGNAL) -2(CONDITION,该节点在condition队列中) -3(PROPAGATE 共享锁模式下的节点状态)

公平锁与非公平锁：
1、在非公平锁中抢占锁的逻是不管有没有线程排队，我先上来cas去抢占一下,成功就表示成功获得了锁,失败则调用acquire(1)走锁竞争逻辑，而公平锁则不会
2、公平锁 tryAcquire中会判断同步队列中当前节点是否有前驱，有的话，需要等待前驱结点释放锁以后才能获取锁
```

##### Condition

```
阻塞：await()方法中，在线程释放锁资源之后，如果节点不在AQS 等待队列，则阻塞当前线程，如果在等待队列，则自旋等待尝试获取锁
释放：signal()后，节点会从 condition 队列移动到 AQS 等待队列，则进入正常锁的获取流程
```


##### 线程池

```
newCachedThreadPool：可缓存线程池，线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。60S回收
newFixedThreadPool：定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
newScheduledThreadPool：定长线程池，支持定时及周期性任务执行。
newSingleThreadExecutor：单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

核心都是：
ThreadPoolExecutor(int corePoolSize,     核心线程数
    int maximumPoolSize,                 最大线程数
    long keepAliveTime,                  超时时间
    TimeUnit unit,                       时间单位
    BlockingQueue<Runnable> workQueue,   阻塞队列
    ThreadFactory threadFactory,         线程工厂
    RejectedExecutionHandler handler)    拒绝策略 
```

##### 多线程下单例模式   

```
1、dobble check instance   
2、static inner class
```
##### HashMap

```
1.7：
    1、结构为数据+链表
    2、默认的负载因子（0.75）
    3、初始大小为16
1.8：
    1、结构为数组+链表+红黑树
    2、默认负载因子为0.75
    3、初始大小为16，链表长度大于8且数组长度大于64就会转换为红黑树
```


##### ConrruentHashMap

```
JDK1.7：
    1、结构为Segment 数组、HashEntry 组成，和HashMap 一样，HashEntry仍然为数据+链表，
    2、Segment控制并发度，默认情况下，可以同时支持 16 个线程的并发写入。且Segment数组初始化后不可扩容
    3、负载因子0.75
jdk1.8：
    1、取消了 segment分段设计，直接使用Node数组来保存数据
    2、采用了 CAS + synchronized 来保证并发安全性
    3、将原本数组+单向链表的数据结构变更为了数组+单向链表+红黑树的结构
    4、初始大小为16，链表长度大于8且数组长度大于64就会转换为红黑树
sizeCtl：
    -1 代表正在初始化
    -N 代表有 N-1 有二个线程正在进行扩容操作
    0 标识 Node数组还没有被初始化，正数代表初始化或者下一次扩容的大小
```

##### CounterCell

```
1、普通通过size计数势必会需要通过加锁或者自旋来保证并发安全，冲突会比较大
2、counterCells如果为空，就通过cas操作尝试修改baseCount变量，对这个变量进行原子累加操作(做这个操作的意义是：如果在没有竞争的情况下，仍然采用baseCount来记录元素个数)
3、如果cas失败说明存在竞争，这个时候不能再采用baseCount来累加，而是通过CounterCell数组来记录
CounterCell数组其实就是分片的思想，CounterCell数组的每个元素，都存储一个元素个数，而实际我们调用size方法就是通过这个循环累加来得到的。
加入一个元素会增加计数，实际是根据当前线程的probe的值和CounterCell数组的大小做与操作，得到CounterCell数组下标，然后对改下标值cas累加
```

#####  ConcurrentHashMap并发扩容
```
分配迁移区间：实现方式是，把Node数组进行拆分，让每个线程处理自己的区域，假设table数组总长度是64，默认情况下，那么每个线程可以分到 16个bucket。然后每个线程处理的范围，按照倒序来做迁移通过 for自循环处理每个槽位中的链表元素，默认advace为真，通过 CAS设置transferIndex属性值，并初始化i和bound值，i 指当前处理的槽位序号，bound指需要处理的槽位边界，先处理槽位 31 的节点；（bound,i）=(16,31)从31的位置往前推动。每处理完一个节点就会设置该节点为ForwardingNode，用于告诉其它线程该槽位已经处理过了；

开始迁移：对数组该节点位置加锁，开始处理数组该位置的迁移工作，具体就是遍历数组每个节点的链表，然后将链表数据构造成高位链和低位链，低位的链表放在i位置也就是不动，将高位链表放在 i+n 位置
高低链可以通过fn&n可得，因为存数据是通过(n-1)&hash值来存储的

长度为 16 的时候，扩容的时候只会有一个线程来扩容
```

